#Run upgrade

apt-get update
 
#Unzip/Build Essentials - GCC Compiler/Python Development/SASL/Pandas
apt-get install unzip build-essential python-dev libsasl2-dev python-pandas binutils

python -V  # should be 2.7x

# install pip
apt-get install python-pip
pip install --upgrade pip



## Install MySQL on Ubuntu
 apt-get install python-dev libmysqlclient-dev mysql-server mysql-client
 pip install MySQL-python


mysql_secure_installation

mysql database	 : anixDb
mysql user 	    : airflowDbUser
mysql user pass	: Airflow!1PW

CREATE DATABASE anixDb CHARACTER SET utf8 COLLATE utf8_unicode_ci;
CREATE USER 'airflowDbUser'@'localhost' IDENTIFIED BY 'Airflow!1PW';
GRANT ALL PRIVILEGES ON * . * TO 'airflowDbUser'@'localhost';
FLUSH PRIVILEGES;

#password change if needed
ALTER USER 'airflowDbUser'@'localhost' IDENTIFIED BY 'Airflow!1PW';

 
###@@@@ Install Airflow and other dependencies

pip install airflow==1.7.0
pip install celery==3.1.17

mkdir /airflow
mkdir /airflow/dags
mkdir /airflow/logs
mkdir /airflow/plugins

vi /etc/bash.bashrc
export AIRFLOW_HOME=/airflow

cd /airflow
airflow initdb

## UPDATE custome config file


# Start Web Server
nohup airflow webserver $* >> /airflow/logs/webserver.logs &

#for stop
for pid in $(ps -ef | grep -e "ww" -e airflow | awk '{print $2}'); do kill -9 $pid; done

#Start Celery Workers
nohup airflow worker $* >> /airflow/logs/celery.logs &

#Start Scheduler
nohup airflow scheduler >> /airflow/logs/scheduler.logs &

#Navigate to the Airflow UI
http://{HOSTNAME}:8080/admin/

##update mysql info in connection at admin menu

#Start Flower (Optional)
#Flower is a web UI built on top of Celery, to monitor your workers.

nohup airflow flower >> /airflow/logs/flower.logs &

#Navigate to the Flower UI (Optional)
http://{HOSTNAME}:5556/
